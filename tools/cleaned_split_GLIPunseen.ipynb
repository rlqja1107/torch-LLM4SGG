{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## GLIP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'licenses', 'images', 'annotations', 'categories'])\n"
     ]
    }
   ],
   "source": [
    "# with open('../DATASET/OpenSource/final_mixed_train_no_coco.json', 'r') as fin: # please refer to https://github.com/microsoft/GLIP for downloading\n",
    "#     res = json.load(fin)\n",
    "with open('../DATASET/OpenSource/final_mixed_train.json', 'r') as fin: # please refer to https://github.com/microsoft/GLIP for downloading\n",
    "    res = json.load(fin)\n",
    "\n",
    "print(res.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2326333.jpg\n",
      "46380\n"
     ]
    }
   ],
   "source": [
    "GLIP_pretraining_vg_images = set([x['file_name'] for x in res['images'] if x['data_source'] == 'vg'])\n",
    "print(list(GLIP_pretraining_vg_images)[0])\n",
    "print(len(GLIP_pretraining_vg_images))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## VG150 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'width': 800, 'url': 'https://cs.stanford.edu/people/rak248/VG_100K_2/1.jpg', 'height': 600, 'image_id': 1, 'coco_id': None, 'flickr_id': None}\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "def load_image_filenames(image_file):\n",
    "    with open(image_file, 'r') as f:\n",
    "        im_data = json.load(f)\n",
    "\n",
    "    corrupted_ims = ['1592.jpg', '1722.jpg', '4616.jpg', '4617.jpg']\n",
    "    fns = []\n",
    "    img_info = []\n",
    "    for i, img in enumerate(im_data):\n",
    "        basename = '{}.jpg'.format(img['image_id'])\n",
    "        if basename in corrupted_ims:\n",
    "            continue\n",
    "\n",
    "        fns.append(basename)\n",
    "        img_info.append(img)\n",
    "    assert len(fns) == 108073\n",
    "    assert len(img_info) == 108073\n",
    "    return fns, img_info\n",
    "\n",
    "fns, img_info = load_image_filenames(\"/home/public/Datasets/CV/vg_bm/image_data.json\")\n",
    "print(img_info[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['active_object_mask', 'attributes', 'boxes_1024', 'boxes_512', 'img_to_first_box', 'img_to_first_rel', 'img_to_last_box', 'img_to_last_rel', 'labels', 'predicates', 'relationships', 'split', 'split_GLIPunseen']>\n",
      "32422\n",
      "75651\n"
     ]
    }
   ],
   "source": [
    "roidb_file = \"/home/public/Datasets/CV/vg_bm/VG-SGG-with-attri.h5\"\n",
    "roi_h5 = h5py.File(roidb_file, 'a')\n",
    "print(roi_h5.keys())\n",
    "\n",
    "data_split = roi_h5['split'][:]\n",
    "print((data_split == 2).sum()) # test split\n",
    "print((data_split == 0).sum()) # train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17985"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(roi_h5['split_GLIPunseen']) ==2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32422"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(roi_h5['split']) ==2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32422\n"
     ]
    }
   ],
   "source": [
    "split_GLIPunseen = np.zeros_like(data_split) # no GLIP training samples in test split\n",
    "\n",
    "test_image_ids = set()\n",
    "for ind, (info, split) in enumerate(zip(img_info, data_split)):\n",
    "    if split == 2:\n",
    "        img_id = info['url'].split('/')[-1].strip()\n",
    "        test_image_ids.add(img_id)\n",
    "        if img_id not in GLIP_pretraining_vg_images:\n",
    "            split_GLIPunseen[ind] = 2 # unseen in GLIP training, as test\n",
    "        else:\n",
    "            split_GLIPunseen[ind] = -2 # seen in GLIP training\n",
    "\n",
    "print(len(test_image_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17985\n"
     ]
    }
   ],
   "source": [
    "vg_test_GLIP_unseen = (test_image_ids - GLIP_pretraining_vg_images)\n",
    "\n",
    "assert (split_GLIPunseen == 2).sum() == len(vg_test_GLIP_unseen)\n",
    "print(len(vg_test_GLIP_unseen))\n",
    "\n",
    "if 'split_GLIPunseen' not in list(roi_h5.keys()):\n",
    "    roi_h5['split_GLIPunseen'] = split_GLIPunseen\n",
    "roi_h5.close()\n",
    "\n",
    "# import h5py\n",
    "# test = h5py.File('test.h5', 'a')\n",
    "# test = h5py.File('test.h5', 'w')\n",
    "# test['split_GLIPunseen'] = split_GLIPunseen\n",
    "# test.close()\n",
    "\n",
    "# test = h5py.File('test.h5', 'r')\n",
    "# test['split_GLIPunseen']\n",
    "# (test['split_GLIPunseen'][:] == 2).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Closed HDF5 file>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_h5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "df955ce39d0f31d56d4bb2fe0a613e5326ba60723fd33d8303a3aede8f65715c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
